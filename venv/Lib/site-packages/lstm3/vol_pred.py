import pandas as pd
import numpy as np
import matplotlib.pylab as plt
from math import sqrt
from matplotlib import pyplot
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics import mean_squared_error
from sklearn.externals import joblib
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import make_pipeline
from keras.models import Sequential
from keras.layers import Dense, LSTM
from pylab import rcParams

import warnings
warnings.filterwarnings("ignore")



def lstm_ttsplit(filename,date_col,response):
    df = pd.read_csv(filename)
    df[date_col] = pd.to_datetime(df[date_col])
    df.set_index(date_col, inplace=True)

    values = df.values
    values = values.astype('float32')

    scaler = MinMaxScaler(feature_range=(0, 1))
    values = scaler.fit_transform(values)

    num_rows = df.shape[0]
    num_train_rows = int(num_rows * 0.75)

    train, test = values[:num_train_rows, :], values[num_train_rows:, :]

    train_X, train_y = train[:, :-1], train[:, -1]
    test_X, test_y = test[:, :-1], test[:, -1]

    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))

    return(train_X,test_X,train_y,test_y)

def lstm_run(train_X,test_X,train_y,test_y):

    model = Sequential()
    model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))
    model.add(Dense(1))
    model.compile(loss='mae', optimizer='adam')

    history = model.fit(train_X, train_y, epochs=500, batch_size=72,
                    validation_data=(test_X, test_y), verbose=0, shuffle=False);

    yhat = model.predict(test_X)

    yhat = [i[0] for i in yhat.tolist()]

    loss, val_loss = history.history['loss'], history.history['val_loss']

    return (loss, val_loss, yhat, test_y)

    
